import argparse
from itertools import chain
from shutil import copyfile, copytree
from tkinter import image_names
from typing import ChainMap
import os
import os.path as osp
import json
from git import rmtree
import numpy as np
import cv2
import math
import ray
from glob import glob
from pathlib import Path
from tqdm import tqdm
from loguru import logger

from utils.data_utils import get_image_crop_resize, get_K_crop_resize
from utils.ray_utils import ProgressBar, chunks
from sample_points_on_cad import sample_points_on_cad
from render_cad_model_to_depth import render_cad_model_to_depth, save_np, depth2color

def parse_args():
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    # Input:
    parser.add_argument(
        "--data_base_dir", type=str, default="/nas/users/hexingyi/onepose_hard_data"
    )
    parser.add_argument("--obj_id", type=str, default="1")
    parser.add_argument("--demo_id", type=str, default="5")
    # parser.add_argument("--split", type=str, default="train", choices=["train", "val"])

    # Output:
    parser.add_argument(
        "--yolo_box_base_path", type=str, default="/nas/users/hexingyi/yolo_real_data"
    )

    args = parser.parse_args()
    return args


def save_json(json_path, data):
    with open(json_path, "w") as output_file:
        json.dump(data, output_file)


def load_json(json_pth):
    assert osp.exists(json_pth), f"json path: {json_pth} not exists!"
    with open(json_pth) as json_file:
        data = json.load(json_file)
    return data

def get_K(intrin_file):
    assert Path(intrin_file).exists()
    with open(intrin_file, 'r') as f:
        lines = f.readlines()
    intrin_data = [line.rstrip('\n').split(':')[1] for line in lines]
    fx, fy, cx, cy = list(map(float, intrin_data))

    K = np.array([
        [fx, 0, cx],
        [0, fy, cy],
        [0,  0,  1]
    ])
    K_homo = np.array([
        [fx, 0, cx, 0],
        [0, fy, cy, 0],
        [0,  0,  1, 0]
    ])
    return K, K_homo

def reproj(K, pose, pts_3d):
    """ 
    Reproj 3d points to 2d points 
    @param K: [3, 3] or [3, 4]
    @param pose: [3, 4] or [4, 4]
    @param pts_3d: [n, 3]
    """
    assert K.shape == (3, 3) or K.shape == (3, 4)
    assert pose.shape == (3, 4) or pose.shape == (4, 4)

    if K.shape == (3, 3):
        K_homo = np.concatenate([K, np.zeros((3, 1))], axis=1)
    else:
        K_homo = K

    if pose.shape == (3, 4):
        pose_homo = np.concatenate([pose, np.array([[0, 0, 0, 1]])], axis=0)
    else:
        pose_homo = pose

    pts_3d = pts_3d.reshape(-1, 3)
    pts_3d_homo = np.concatenate([pts_3d, np.ones((pts_3d.shape[0], 1))], axis=1)
    pts_3d_homo = pts_3d_homo.T

    reproj_points = K_homo @ pose_homo @ pts_3d_homo
    depth = reproj_points[2]  # [N]
    reproj_points = reproj_points[:] / reproj_points[2:]
    reproj_points = reproj_points[:2, :].T

    return reproj_points, depth  # [n, 2]


def parse_models_info_txt(models_info_txt_path):
    models_info_dict = {}
    with open(models_info_txt_path, "r") as f:
        txt_list = f.readlines()
        for obj_info in txt_list:
            obj_info_splited = obj_info.split(" ")
            obj_id = obj_info_splited.pop(0)
            model_info = {}
            for id in range(0, len(obj_info_splited), 2):
                model_info[obj_info_splited[id]] = float(obj_info_splited[id + 1])
            models_info_dict[obj_id] = model_info
    return models_info_dict

def get_3d_box_scale(bbox_path):
    """ Read box rotation and translation from box file generated by ObjectScanner"""
    from scipy.spatial.transform import Rotation

    def parse_bbox(bbox_path):
        with open(bbox_path) as f:
            lines = f.readlines()
        data = [float(e) for e in lines[1].strip().split(',')]
        return data
    
    bbox_data = np.array(parse_bbox(bbox_path))
    tvec, qvec, scale = bbox_data[:3], bbox_data[-4:], bbox_data[3:6]
    
    scale = scale.reshape(3, )
    return scale

def get_3d_box(bbox_path):
    """ Get 3d box corners in canonical coordinate """
    try:
        tvec, rvec, scale = get_3d_box_pose(bbox_path)
        rotation = cv2.Rodrigues(rvec)[0]
    except:
        # Extract scale only!
        logger.warning(f"Can only extract scale data from bbox path:{bbox_path}")
        scale = get_3d_box_scale(bbox_path)
        rotation = np.eye(3)
        tvec = np.zeros((3,1))

    T = np.hstack((rotation, tvec))
    T = np.vstack((T, np.array([0, 0, 0, 1])))

    corner_in_cano = np.array([
        [-scale[0], -scale[0], -scale[0], -scale[0],  scale[0],  scale[0],  scale[0],  scale[0]],
        [-scale[1], -scale[1],  scale[1],  scale[1], -scale[1], -scale[1],  scale[1],  scale[1]],
        [-scale[2],  scale[2],  scale[2], -scale[2], -scale[2],  scale[2],  scale[2], -scale[2]],
        [1, 1, 1, 1, 1, 1, 1, 1]
    ]).T
    corner_in_cano = corner_in_cano[:, :3] * 0.5
    return corner_in_cano, T


if __name__ == "__main__":
    args = parse_args()
    object_names = os.listdir(args.data_base_dir)
    id2full_name = {name[:4]: name for name in object_names if "-" in name}

    obj_full_name = id2full_name[args.obj_id]
    obj_name = obj_full_name.split('-',2)[1]

    logger.info(f"Working on obj:{obj_full_name}")

    seq_dir = osp.join(
        args.data_base_dir,
        obj_full_name,
        '-'.join([obj_name,args.demo_id]),
    )
    image_seq_dir = osp.join(seq_dir,'color_full')

    # Parse bbox size and save:
    origin_seq_dir = osp.join(
        args.data_base_dir,
        obj_full_name,
        '-'.join([obj_name,'1']),
    )
    bbox_path = osp.join(origin_seq_dir, "Box.txt")
    box_corner, _ = get_3d_box(bbox_path)
    np.savetxt(osp.join(seq_dir,'Box_corner.txt'), box_corner)
        
    assert osp.exists(image_seq_dir)
    rgb_names = os.listdir(image_seq_dir)

    # Construct output data file structure
    output_color_crop_dir = osp.join(seq_dir, 'color')
    output_intrin_dir = osp.join(seq_dir, 'intrin_ba')
    output_intrin_fakeorigin_dir = osp.join(seq_dir, 'intrin')
    if osp.exists(output_color_crop_dir):
        rmtree(output_color_crop_dir)
    if osp.exists(output_intrin_dir):
        rmtree(output_intrin_dir)
    if osp.exists(output_intrin_fakeorigin_dir):
        rmtree(output_intrin_fakeorigin_dir)
    Path(output_color_crop_dir).mkdir(parents=True, exist_ok=True,)
    Path(output_intrin_dir).mkdir(parents=True, exist_ok=True)
    Path(output_intrin_fakeorigin_dir).mkdir(parents=True, exist_ok=True)

    if not osp.exists(osp.join(seq_dir, 'poses_ba')):
        copytree(osp.join(seq_dir, 'poses'), osp.join(seq_dir, 'poses_ba'))

    img_id = 0
    for global_id, rgb_name in tqdm(enumerate(rgb_names), total=len(rgb_names)):
        dataset_img_id, img_ext = osp.splitext(rgb_name)
        K, _ = get_K(osp.join(image_seq_dir.replace('color_full', 'intrinsics.txt')))
        # K = np.array([[572.4114, 0, 325.2611], [0, 573.57043, 242.04899], [0, 0, 1]])
        # pose = np.loadtxt(
        #     osp.join(image_seq_dir, "-".join([dataset_img_id, "pose"]) + ".txt")
        # )
        img_path = osp.join(image_seq_dir, rgb_name)
        original_img = cv2.imread(img_path)
        img_h, img_w = original_img.shape[:2]


        # Load yolo box:
        yolo_box_obj_path = osp.join(args.yolo_box_base_path, 'detect_demo', obj_full_name, 'labels')
        yolo_box_file_path = osp.join(yolo_box_obj_path, dataset_img_id+'.txt')
        if not osp.exists(yolo_box_file_path):
            logger.warning(f"yolo box:{yolo_box_file_path} not exists, jump!!")
            continue
        yolo_box = np.loadtxt(yolo_box_file_path)
        assert yolo_box.shape[0] != 0, f"img id:{dataset_img_id} no box detected!"
        if len(yolo_box.shape) == 2:
            # not only box! select by maxium confidence
            want_id = np.argsort(yolo_box[:,5])[0]
            yolo_box = yolo_box[want_id]
        
        x_c_n, y_c_n, w_n, h_n = yolo_box[1:5]
        x0_n, y0_n = x_c_n - w_n / 2, y_c_n - h_n /2

        x0, y0, w, h = int(x0_n * img_w), int(y0_n * img_h), int(w_n * img_w), int(h_n * img_h)
        x1, y1 = x0 + w, y0 + h


        # Crop image by 2D visible bbox, and change K
        box = np.array([x0, y0, x1, y1])
        resize_shape = np.array([y1 - y0, x1 - x0])
        K_crop, K_crop_homo = get_K_crop_resize(box, K, resize_shape)
        image_crop, _ = get_image_crop_resize(original_img, box, resize_shape)

        box_new = np.array([0, 0, x1 - x0, y1 - y0])
        # resize_shape = np.array([256, 256])  # FIXME: change to global configs
        resize_shape = np.array([512, 512])  # FIXME: change to global configs
        K_crop, K_crop_homo = get_K_crop_resize(box_new, K_crop, resize_shape)
        image_crop, _ = get_image_crop_resize(image_crop, box_new, resize_shape)

        cv2.imwrite(osp.join(output_color_crop_dir, str(dataset_img_id) + img_ext), image_crop)
        np.savetxt(osp.join(output_intrin_dir, str(dataset_img_id) + ".txt"), K_crop)
        np.savetxt(osp.join(output_intrin_fakeorigin_dir, str(dataset_img_id) + ".txt"), K_crop)
