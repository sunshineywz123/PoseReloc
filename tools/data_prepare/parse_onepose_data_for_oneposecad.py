import argparse
from itertools import chain
from typing import ChainMap
import os
import os.path as osp
import json
import numpy as np
from loguru import logger
import cv2
import math
import ray
from tqdm import tqdm

from utils.ray_utils import ProgressBar, chunks
from sample_points_on_cad import sample_points_on_cad
from render_cad_model_to_depth import render_cad_model_to_depth, save_np, depth2color

dataset_name2model_dict = {
    "ycbv": "models",
    "lm": "models",
    "tless": "models_cad",
}
ext_bag = [".png", ".jpg"]


def parse_args():
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    # Input:
    parser.add_argument(
        "--data_base_dir", type=str, default="/nas/users/hexingyi/onepose_hard_data"
    )
    parser.add_argument("--obj_id", type=str, default="0607")
    parser.add_argument("--seq_ids", type=str, default="1", help="split by ,")
    parser.add_argument("--split", type=str, default="train", choices=["train", "val"])

    # Output:
    parser.add_argument(
        "--output_json_dir", type=str, default="/nas/users/hexingyi/onepose_cad_json"
    )

    # Ray related
    parser.add_argument("--use_ray", action="store_true")
    parser.add_argument("--slurm", action="store_true")
    parser.add_argument("--n_workers", type=int, default=15)
    parser.add_argument("--n_cpus_per_worker", type=float, default=2)
    parser.add_argument(
        "--local_mode", action="store_true", help="ray local mode for debugging."
    )

    args = parser.parse_args()
    return args


def save_json(json_path, data):
    with open(json_path, "w") as output_file:
        json.dump(data, output_file)


def load_json(json_pth):
    assert osp.exists(json_pth), f"json path: {json_pth} not exists!"
    with open(json_pth) as json_file:
        data = json.load(json_file)
    return data


def reproj(K, pose, pts_3d):
    """ 
    Reproj 3d points to 2d points 
    @param K: [3, 3] or [3, 4]
    @param pose: [3, 4] or [4, 4]
    @param pts_3d: [n, 3]
    """
    assert K.shape == (3, 3) or K.shape == (3, 4)
    assert pose.shape == (3, 4) or pose.shape == (4, 4)

    if K.shape == (3, 3):
        K_homo = np.concatenate([K, np.zeros((3, 1))], axis=1)
    else:
        K_homo = K

    if pose.shape == (3, 4):
        pose_homo = np.concatenate([pose, np.array([[0, 0, 0, 1]])], axis=0)
    else:
        pose_homo = pose

    pts_3d = pts_3d.reshape(-1, 3)
    pts_3d_homo = np.concatenate([pts_3d, np.ones((pts_3d.shape[0], 1))], axis=1)
    pts_3d_homo = pts_3d_homo.T

    reproj_points = K_homo @ pose_homo @ pts_3d_homo
    depth = reproj_points[2]  # [N]
    reproj_points = reproj_points[:] / reproj_points[2:]
    reproj_points = reproj_points[:2, :].T

    return reproj_points, depth  # [n, 2]


def parse_data_for_obj(
    data_base_dir, obj_name, seq_name, split, verbose=True
):
    """
    obj_base_dir:
        obj_name(id_name_cato):
        - model.ply
            - seq_name0
                - color
                - mask_visib
                - obj_depth (generated by this func by setting save_obj_depth flag to `True`)
            - seq_name1
    """
    # save_obj_depth = (
    #     split == "train"
    # )  # save obj depth for making corrspondence GT in training
    save_obj_depth = True
    seq_dir = osp.join(
        data_base_dir,
        obj_name,
        seq_name,
    )
    obj_id = obj_name.split('-')[0]

    img_dir = osp.join(seq_dir, "color")
    cad_model_path = osp.join(data_base_dir, obj_name, 'model.ply')
    obj_depth_dir = osp.join(seq_dir, "obj_depth")
    obj_mask_dir = osp.join(seq_dir, "obj_mask")

    os.makedirs(obj_depth_dir, exist_ok=True)
    os.makedirs(obj_mask_dir, exist_ok=True)
    assert osp.exists(img_dir)

    all_img_names = [img_name for img_name in os.listdir(img_dir) if '_' not in img_name]
    if len(all_img_names) == 0:
        logger.info(f"No image in {osp.join(data_base_dir, obj_name)}")
        return {}

    result_dic = {}
    all_img_names = tqdm(all_img_names) if verbose else all_img_names
    for global_id, img_name in enumerate(all_img_names):
        # if global_id > 100:
        #     break

        img_path = osp.join(img_dir, img_name)
        img_id = osp.splitext(img_name)[0]

        T_m2c = np.loadtxt(osp.join(seq_dir, 'poses_ba', img_id + '.txt')) # 4*4
        R_m2c = T_m2c[:3, :3] # 3*3
        t_m2c = T_m2c[:3, [3]] # 3*1
        K = np.loadtxt(osp.join(seq_dir, 'intrin_ba', img_id + '.txt')) # 4*4

        # Load CAD model and sample points
        assert osp.exists(cad_model_path)

        points_sampled, _ = sample_points_on_cad(cad_model_path, 5000)
        sampled_points_rpj, sampled_depth = reproj(
            K, np.concatenate([R_m2c, t_m2c], axis=-1), points_sampled
        )

        result_dic[
            "###".join(
                [
                    cad_model_path.replace(data_base_dir + "/", ""),
                    img_path.replace(data_base_dir + "/", ""),
                ]
            )
        ] = {
            "R_m2c": R_m2c.tolist(),
            "t_m2c": t_m2c.tolist(),
            "K": K.tolist(),
            "split_patten": "###",  # Used for split cat model path and image path from dict key.
        }

        if save_obj_depth:
            # Render depth according to object:
            image = cv2.imread(img_path)
            H, W = image.shape[:2]
            depth_range = np.max(sampled_depth) - np.min(sampled_depth)

            depth = render_cad_model_to_depth(
                cad_model_path,
                K,
                [R_m2c, t_m2c],
                H,
                W,
                # depth_img_save_path="depth.png",
                depth_range_prior=[
                    np.min(sampled_depth) - 0.1 * depth_range,
                    np.max(sampled_depth) + 0.1 * depth_range,
                ],
                # depth_img_save_path='depth.png',
                # mask_img_save_path='mask.png'
                mask_img_save_path=osp.join(obj_mask_dir, img_id+'.png')
            )

            # # Debug: mask image:
            # mask = cv2.imread('mask.png')
            # masked_image = cv2.addWeighted(image, 0.7, mask, 0.3, 0)
            # cv2.imwrite('masked_img.png', masked_image)

            obj_depth_path = osp.join(
                obj_depth_dir,
                img_id + ".npy",
            )
            save_np(depth, obj_depth_path)

            result_dic[
                "###".join(
                    [
                        cad_model_path.replace(data_base_dir + "/", ""),
                        img_path.replace(data_base_dir + "/", ""),
                    ]
                )
            ].update(
                {
                    "obj_depth_relative_path": osp.join(
                        obj_depth_dir,
                        img_id + ".npy",
                    ).replace(data_base_dir + "/", ""),
                }
            )
            # Debug visual color depth:
            # color_depth = depth2color(depth)
            # color_depth.save('depth.png')

    return result_dic

def parse_data_for_obj_multiple_seqs(
    data_base_dir, obj_name, seq_dir_list, split, pba=None
):
    results_seq_list = []
    seq_dir_list = tqdm(seq_dir_list) if pba is None else seq_dir_list
    for seq_name in seq_dir_list:
        result_dir = parse_data_for_obj(
            data_base_dir, obj_name, seq_name, split=split,
        )
        results_seq_list += [result_dir]

        if pba is not None:
            pba.update.remote(1)
    return results_seq_list


@ray.remote(num_cpus=2)
def parse_data_for_obj_multiple_seqs_ray_wrapper(*args, **kwargs):
    return parse_data_for_obj_multiple_seqs(*args, **kwargs)


if __name__ == "__main__":
    args = parse_args()
    data_base_dir = args.data_base_dir
    all_obj_names = os.listdir(data_base_dir)
    id2full_name = {name[:4]: name for name in all_obj_names if "-" in name}

    # Get obj full name(obj dir name) from obj id
    assert args.obj_id in id2full_name
    id_name_cato = id2full_name[args.obj_id]
    id, obj_name, cato = id_name_cato.split("-", 2)

    # Merge images from multiple seqs:
    seq_ids = args.seq_ids.split(",")  # List [id0, id1...]
    seq_names = ['-'.join([obj_name, seq_id]) for seq_id in seq_ids]
    
    if args.use_ray:
        raise NotImplementedError
        if args.slurm:
            ray.init(address=os.environ["ip_head"])
        else:
            ray.init(
                num_cpus=math.ceil(args.n_workers * args.n_cpus_per_worker),
                # num_gpus=math.ceil(args.n_workers * args.n_gpus_per_worker),
                local_mode=args.local_mode,
            )

        pb = ProgressBar(
            len(seq_dir_list),
            f"Parse bop data set: {args.dataset_name}, obj:{args.obj_id}...",
        )
        all_subsets = chunks(
            seq_dir_list, math.ceil(len(seq_dir_list) / args.n_workers)
        )

        results = [
            parse_data_for_obj_multiple_seqs_ray_wrapper.remote(
                args.data_base_dir,
                args.dataset_name,
                subsets,
                obj_id=args.obj_id,
                split=args.split,
                pba=pb.actor,
            )
            for subsets in all_subsets
        ]
        pb.print_until_done()
        results_seq_list = list(chain(*ray.get(results)))
    else:
        results_seq_list = parse_data_for_obj_multiple_seqs(
            data_base_dir,
            id_name_cato,
            seq_names,
            split=args.split,
            pba=None,
        )

    results_dict = dict(ChainMap(*results_seq_list))

    output_json_dir = args.output_json_dir
    os.makedirs(output_json_dir, exist_ok=True)
    save_json(
        osp.join(
            output_json_dir, f"{args.split}_onepose_{args.obj_id}.json"
        ),
        results_dict,
    )  # datasetName_objID.json
