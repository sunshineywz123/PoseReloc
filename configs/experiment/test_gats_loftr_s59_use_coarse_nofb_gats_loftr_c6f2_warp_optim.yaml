# @package _global_

type: inference

data_base_dir: "/cephfs-mvs/3dv-research/hexingyi/arscan_aligned/arscan_data"
sfm_base_dir: "/cephfs-mvs/3dv-research/hexingyi/onepose_sfm_v3"

match_type: softmax
task_name: test_loftr_gats_test_hard_0.1_7000_3d_train_use_coarse_nofb_gats_loftr_c6f2_warp_no_pad_optim
suffix: ""
feature_method: "average"

use_global_ray: True
use_local_ray: True

ray:
  slurm: False
  n_workers: 2
  n_cpus_per_worker: 5
  n_gpus_per_worker: 1
  local_mode: False

# TODO: merge from train.yaml
model:
  # _target_: src.models.spg_model.LitModelSPG
  _target_: src.models.GATs_LoFTR_lightning_model.PL_GATsLoFTR
  pretrained_ckpt: /cephfs-mvs/3dv-research/hexingyi/code/PoseReloc/models/checkpoints/train_coarse_thr_0.4_layernorm_n_head_8_finew5_fix_backbone_no_hard_train_7000_3d_use_coarse_nofb_no_fineatt_pe_linear_gat_loftr_c6f2_warp/epoch=13.ckpt

  loftr:
    loftr_backbone:
      type: "ResNetFPN"
      resolution: [8, 2]
      resnetfpn:
        block_type: "BasicBlock"
        initial_dim: 128
        block_dims: [128, 196, 256]
        output_layers: [3, 1]

      pretrained: "weight/loftr_w9_no_cat_coarse_auc10=0.685.ckpt"
      pretrained_fix: False

    use_fine_backbone_as_coarse: False
    interpol_type: "bilinear" # ['nearest', 'bilinear']

    keypoints_encoding:
      enable: True
      type: mlp_linear # ['mlp_cov1d', 'mlp_linear']
      descriptor_dim: 256
      keypoints_encoder: [32, 64, 128]
      norm_method: "instancenorm"

    positional_encoding:
      enable: True
      pos_emb_shape: [256, 256]
    loftr_coarse:
      type: "LoFTR"
      # type: 'LoFTR-Conv1d'
      d_model: 256
      d_ffm: 128
      nhead: 8
      # nhead: 8
      # layer_names: ['Pe', 'self', 'cross']
      # layer_names: ["self", "cross"]
      layer_names: ["GATs","self", "cross"]
      layer_iter_n: 6
      dropout: 0.
      attention: "linear"
      norm_method: "layernorm"
      # norm_method: 'instancenorm'

      kernel_fn: "elu + 1" # ['elu + 1', 'Favor', 'GeneralizedRandomFeatures']
      d_kernel: 16 # (128 / 8)
      redraw_interval: 2
      rezero: null
      final_proj: False

      # GATs part
      GATs_type: 'loftr_attention' # ["origin_gats", 'loftr_attention']
      GATs_include_self: False
      # useful for loftr_attention:
      GATs_feat2d_db_update: True
      # useful for origin_gats:
      d_db_feat: 256 # The input dim of database feature
      GATs_dropout: 0.6
      GATs_alpha: 0.2
      GATs_enable_feed_forward: False
      GATs_feed_forward_norm_method: 'instancenorm'

      # Pe part:
      d_model_2D: 256
      max_shape_2D: [256, 256]
      feature_dim_3D: 256
      keypoints_encoder_3D: [32, 64, 128]
      norm_method_3D: "instancenorm"
      encoding_type_3D: sine # ['mlp_cov1d', 'mlp_linear', 'sine']

    coarse_matching:
      type: "dual-softmax"
      # type: 'sinkhorn'
      thr: 0.1
      feat_norm_method: "sqrt_feat_dim"
      border_rm: 2
      spg_spvs: False

      skh:
        fp16: False
        iters: 20
        partial_impl: "dustbin"
        init_bin_score: 1.0
        prototype_impl: "learned"
        prefilter: True
        with_prior: False
        linear:
          enable: False
          mapping: "favor"
          mapping_dim: 4096

      dual_softmax:
        temperature: 0.08
        temperature_learnable: False
        range: # may be log range or exp range?
          - 0.03 # min
          - 0.8 # max

      train:
        train_padding: True # Good to be true
        # From LoFTR:
        train_coarse_percent: 0.3 # save GPU memory
        train_pad_num_gt_min: 200 # avoid deadlock; better convergence

    loftr_fine:
      enable: True
      # Fine preprocess:
      window_size: 5
      concat_coarse_feat: False
      concat_coarse_feat_type: "nearest"
      coarse_layer_norm: False
      ms_feat: False
      ms_feat_type: 'PROJ_MERGE'

      # Fine module
      type: "LoFTR"
      d_model: 128
      nhead: 8
      # layer_names: ["self", "cross"]
      layer_names: ["GATs","self", "cross"]
      layer_iter_n: 2
      dropout: 0.0
      attention: "linear"
      norm_method: layernorm

      kernel_fn: "elu + 1"
      d_kernel: 16
      redraw_interval: 2
      rezero: null
      final_proj: False

      # GATs part
      GATs_type: 'loftr_attention' # ["origin_gats", 'loftr_attention']
      GATs_include_self: False
      # useful for loftr_attention
      GATs_feat2d_db_update: True
      # useful for origin_gats
      d_db_feat: 128 # The input dim of database feature
      GATs_dropout: 0.6
      GATs_alpha: 0.2
      GATs_enable_feed_forward: False
      GATs_feed_forward_norm_method: 'instancenorm'

    fine_matching:
        enable: True
        type: 's2d'
        detector: 'OnGrid'

        s2d:
            type: 'heatmap'

  loss:
    spg_spvs: False
    coarse_type: "focal"
    coarse_weight: 1.0
    fine_type: "l2_with_std"
    fine_weight: 0.81 # Calculated according to fine window size in train_gats_loftr.py

    # Config for coarse
    focal_alpha: 0.5 # 0.25 default
    focal_gamma: 2.0
    pos_weight: 1.0
    neg_weight: 1.0

    # smooth_l1_with_std
    fine_smooth_l1_beta: 1.0
    fine_loss_weight: 1.0
    fine_correct_thr: 1.0

  trainer:
    enable_plotting: True
    canonical_bs: 4
    canonical_lr: 5e-4
    scaling: null
    world_size: null
    n_val_pairs_to_plot: 50

    # Optimizer
    optimizer: "adamw" # ['adam', 'adamw']
    true_lr: null
    adam_decay: 0.
    adamw_decay: 0.1

    # Scheduler
    scheduler: "MultiStepLR"
    scheduler_invervel: "epoch"
    mslr_milestones: [5,8,11,18]
    mslr_gamma: 0.5
    cosa_tmax: 30
    elr_gamma: 0.999992

  eval_metrics:
    point_cloud_rescale: 1000
    pnp_reprojection_error: 8
    pose_thresholds: [1, 3, 5, 7]
    enable_post_optimization: True
    post_optimization_configs:
      # residual_mode: 'feature_metric_error'
      residual_mode: 'geometry_error'
      use_fine_pose_as_init: True
      solver_type: 'FirstOrder'
      distance_loss_scale: 80
      # optimize_lr: 1e-4
      optimize_lr: 8e-4
      max_steps: 200
      image_i_f_scale: 2
      verbose: False

  match_type: "softmax"

# TODO: remove
datamodule:
    _target_: src.datamodules.GATs_loftr_datamodule.GATsLoFTRDataModule
    # data_dirs: ${sfm_dir}
    anno_dirs: outputs_${model.match_type}/anno
    train_anno_file: ${merge_output_dir}/${task_name}/train.json
    val_anno_file: ${merge_output_dir}/${task_name}/val.json

    batch_size: 3
    num_workers: 4
    pin_memory: True

    train_percent: 1.0 # For debug
    val_percent: 0.2

    # TODO: move to a template
    # 3D part
    num_leaf: 8
    shape2d: 2000 # Not used
    shape3d_train: 10000 # NOTE: Changed from 11000 to 12000
    shape3d_val: 10000 # 15000
    load_3d_coarse: True
    pad3D: False

    # 2D part
    img_pad: False
    img_resize: [512, 512]
    df: 8
    coarse_scale: 0.125

    # File path substitute:
    path_prefix_substitute_3D_source: null
    path_prefix_substitute_3D_aim: null
    path_prefix_substitute_2D_source: null
    path_prefix_substitute_2D_aim: null

network:
  detection: loftr
  matching: loftr

data_dir: ${data_base_dir}
top_k_obj: null
num_val_seq: 1 # last n objects
ids:
    # - '0408'
    # - '0409'
    # - '0419'
    # - '0422'
    # - '0423'
    # - '0424'
    # - '0447'
    # - '0450'
    # - '0452'
    # - '0455'
    # - '0456'
    # - '0458'
    # - '0459'
    # - '0466'
    # - '0468'
    # - '0469'
    # - '0470'
    # - '0471'
    # - '0472'
    # - '0473'
    # - '0474'
    # - '0476'
    # - '0480'
    # - '0483'
    # - '0486'
    # - '0487'
    # - '0488'
    # - '0489'
    # - '0490'
    # - '0492'
    # - '0493'
    # - '0494'
    # - '0495'
    # - '0496'
    # - '0497'
    # - '0498'
    # - '0500'
    # - '0501'
    # - '0502'
    # - '0503'
    # - '0504'
    # - '0508'
    # - '0510'
    # - '0511'
    # - '0517'
    # - '0518'
    # - '0519'
    # - '0520'
    # - '0521'
    # - '0522'
    # - '0523'
    # - '0525'
    # - '0526'
    # - '0527'
    # - '0534'
    # - '0535'
    # - '0537'
    # - '0539'
    # - '0543'
    # - '0547'
    # - '0548'
    # - '0550'
    # - '0551'
    # - '0552'
    # - '0557'
    # - '0558'
    # - '0559'
    # - '0560'
    # - '0564'
    # - '0565'
    # - '0568'
    # - '0570'
    # - '0576'
    # - '0577'
    # - '0578'
    # - '0579'
    # - '0580'
    # - '0582'
    # - '0583'
    # - '0593'
    # - '0594'
    # - '0595'

    # # test hard
    - '0601'
    - '0603'
    - '0604'
    # - '0605' # pingpang too hard!
    - '0626'
    - '0627'
    - '0628'
    - '0629'
    - '0630'
    - '0631'
    # - '0632' # chair too hard
    # From train objects
    - '0600'
    - '0602'
    - '0606'
    - '0607'
    - '0608'
    - '0610'

    - '0612'
    - '0613'
    - '0614'
    - '0615'
    - '0616'
    - '0617'

    - '0618'
    - '0619'
    - '0620'
    - '0621'
    - '0622'
    - '0623'
    - '0624'
    - '0625'
    - '0633'
    - '0634'
    - '0635'
    - '0636'
    - '0637'
    - '0638'

    # Train objects
    # - '0410'
    # - '0413'
    # - '0414'
    # - '0415'
    # - '0416'
    # - '0418'
    # - '0420'
    # - '0421'
    # - '0443'
    # - '0445'
    # - '0448'
    # - '0460' # Problem exists for this data! no box trans, no intrin_ba, don't use!
    # - '0461'
    # - '0462'
    # - '0463'
    # - '0464'
    # - '0465'
    # - '0477'
    # - '0479'
    # - '0484'
    # - '0499'
    # - '0506'
    # - '0507'
    # - '0509'
    # - '0512'
    # - '0513'
    # - '0516'
    # - '0529'
    # - '0530'
    # - '0531'
    # - '0532'
    # - '0533'
    # - '0536'
    # - '0542'
    # - '0545'
    # - '0546'
    # - '0549'
    # - '0556'
    # - '0561'
    # - '0562'
    # - '0563'
    # - '0566'
    # - '0567'
    # - '0569'
    # - '0571'
    # - '0572'
    # # - '0573'
    # - '0574'
    # - '0575'

    # # Train hard objects
    # - '0600'
    # - '0602'
    # - '0606'
    # - '0607'
    # - '0608'
    # - '0610'

    # - '0612'
    # - '0613'
    # - '0614'
    # - '0615'
    # - '0616'
    # - '0617'

    # - '0618'
    # - '0619'
    # - '0620'
    # - '0621'
    # - '0622'
    # - '0623'
    # - '0624'
    # - '0625'
exception_obj_names: 
    -

verbose: False

output:
  txt_dir: '/cephfs-mvs/3dv-research/hexingyi/onepose_test/${task_name}'
  visual_vis3d: False # NOTE: will be slow
  vis_dir: '/cephfs-mvs/3dv-research/hexingyi/onepose_test/${task_name}/vis3d'
